
The following modules were not unloaded:
   (Use "module --force purge" to unload all):

  1) XALT/minimal   2) slurm   3) NeSI
2024-04-22 00:49:46.859779: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-22 00:49:46.859859: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-22 00:49:46.859890: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-22 00:49:46.869394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-22 00:49:50.284054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38298 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:05:00.0, compute capability: 8.0
1 Physical GPUs, 1 Logical GPUs
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv1d (Conv1D)             (None, 1048576, 64)       8256      
                                                                 
 conv1d_1 (Conv1D)           (None, 131072, 64)        262208    
                                                                 
 conv1d_2 (Conv1D)           (None, 16384, 64)         262208    
                                                                 
 conv1d_transpose (Conv1DTr  (None, 131072, 64)        262208    
 anspose)                                                        
                                                                 
 conv1d_transpose_1 (Conv1D  (None, 1048576, 64)       262208    
 Transpose)                                                      
                                                                 
 conv1d_transpose_2 (Conv1D  (None, 8388608, 2)        8194      
 Transpose)                                                      
                                                                 
 activation (Activation)     (None, 8388608, 2)        0         
                                                                 
=================================================================
Total params: 1065282 (4.06 MB)
Trainable params: 1065282 (4.06 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
#################################
####DATA GENERATOR PARAMETERS####
#Dataset size:  11011
#Batch size:  8
#Time in years: 2.658143162020893
#n_channels:  2
#dt:  10
#Length of timeseries: 8388608
Noise background:  False
#################################
Epoch 1/100
2024-04-22 00:50:19.955679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600
2024-04-22 00:51:34.973437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ab5f86c18a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-04-22 00:51:34.973519: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0
2024-04-22 00:51:34.989208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-04-22 00:51:35.481140: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
10/10 - 140s - loss: 0.1496 - val_loss: 0.6346 - 140s/epoch - 14s/step
Epoch 2/100
10/10 - 63s - loss: 0.0498 - val_loss: 0.0306 - 63s/epoch - 6s/step
Epoch 3/100
10/10 - 65s - loss: 0.0465 - val_loss: 0.0436 - 65s/epoch - 6s/step
Epoch 4/100
10/10 - 64s - loss: 0.0409 - val_loss: 0.0343 - 64s/epoch - 6s/step
Epoch 5/100
10/10 - 64s - loss: 0.0271 - val_loss: 0.0263 - 64s/epoch - 6s/step
Epoch 6/100
10/10 - 65s - loss: 0.0223 - val_loss: 0.0210 - 65s/epoch - 6s/step
Epoch 7/100
10/10 - 63s - loss: 0.0282 - val_loss: 0.0303 - 63s/epoch - 6s/step
Epoch 8/100
10/10 - 64s - loss: 0.0383 - val_loss: 0.0378 - 64s/epoch - 6s/step
Epoch 9/100
10/10 - 64s - loss: 0.0275 - val_loss: 0.0271 - 64s/epoch - 6s/step
Epoch 10/100
10/10 - 69s - loss: 0.0320 - val_loss: 0.0320 - 69s/epoch - 7s/step
Epoch 11/100
10/10 - 90s - loss: 0.0223 - val_loss: 0.0223 - 90s/epoch - 9s/step
Epoch 12/100
10/10 - 90s - loss: 0.0253 - val_loss: 0.0247 - 90s/epoch - 9s/step
Epoch 13/100
10/10 - 64s - loss: 0.0220 - val_loss: 0.0218 - 64s/epoch - 6s/step
Epoch 14/100
10/10 - 66s - loss: 0.0145 - val_loss: 0.0145 - 66s/epoch - 7s/step
Epoch 15/100
10/10 - 73s - loss: 0.0199 - val_loss: 0.0197 - 73s/epoch - 7s/step
Epoch 16/100
10/10 - 90s - loss: 0.0232 - val_loss: 0.0229 - 90s/epoch - 9s/step
Epoch 17/100
10/10 - 62s - loss: 0.0176 - val_loss: 0.0176 - 62s/epoch - 6s/step
Epoch 18/100
10/10 - 64s - loss: 0.0214 - val_loss: 0.0209 - 64s/epoch - 6s/step
Epoch 19/100
10/10 - 64s - loss: 0.0228 - val_loss: 0.0225 - 64s/epoch - 6s/step
Epoch 20/100
10/10 - 65s - loss: 0.0243 - val_loss: 0.0236 - 65s/epoch - 7s/step
Epoch 21/100
10/10 - 63s - loss: 0.0191 - val_loss: 0.0177 - 63s/epoch - 6s/step
Epoch 22/100
10/10 - 63s - loss: 0.0175 - val_loss: 0.0166 - 63s/epoch - 6s/step
Epoch 23/100
10/10 - 62s - loss: 0.0188 - val_loss: 0.0184 - 62s/epoch - 6s/step
Epoch 24/100
10/10 - 64s - loss: 0.0129 - val_loss: 0.0114 - 64s/epoch - 6s/step
Epoch 25/100
10/10 - 62s - loss: 0.0147 - val_loss: 0.0142 - 62s/epoch - 6s/step
Epoch 26/100
10/10 - 63s - loss: 0.0133 - val_loss: 0.0131 - 63s/epoch - 6s/step
Epoch 27/100
10/10 - 64s - loss: 0.0168 - val_loss: 0.0155 - 64s/epoch - 6s/step
Epoch 28/100
10/10 - 66s - loss: 0.0146 - val_loss: 0.0196 - 66s/epoch - 7s/step
Epoch 29/100
10/10 - 65s - loss: 0.0121 - val_loss: 0.0120 - 65s/epoch - 7s/step
Epoch 30/100
10/10 - 64s - loss: 0.0122 - val_loss: 0.0120 - 64s/epoch - 6s/step
Epoch 31/100
10/10 - 64s - loss: 0.0118 - val_loss: 0.0110 - 64s/epoch - 6s/step
Epoch 32/100
10/10 - 64s - loss: 0.0111 - val_loss: 0.0107 - 64s/epoch - 6s/step
Epoch 33/100
10/10 - 63s - loss: 0.0124 - val_loss: 0.0127 - 63s/epoch - 6s/step
Epoch 34/100
10/10 - 63s - loss: 0.0105 - val_loss: 0.0106 - 63s/epoch - 6s/step
Epoch 35/100
10/10 - 65s - loss: 0.0089 - val_loss: 0.0089 - 65s/epoch - 6s/step
Epoch 36/100
10/10 - 62s - loss: 0.0108 - val_loss: 0.0106 - 62s/epoch - 6s/step
Epoch 37/100
10/10 - 64s - loss: 0.0088 - val_loss: 0.0086 - 64s/epoch - 6s/step
Epoch 38/100
10/10 - 64s - loss: 0.0078 - val_loss: 0.0077 - 64s/epoch - 6s/step
Epoch 39/100
10/10 - 61s - loss: 0.0109 - val_loss: 0.0106 - 61s/epoch - 6s/step
Epoch 40/100
10/10 - 62s - loss: 0.0135 - val_loss: 0.0135 - 62s/epoch - 6s/step
Epoch 41/100
10/10 - 66s - loss: 0.0081 - val_loss: 0.0091 - 66s/epoch - 7s/step
Epoch 42/100
10/10 - 64s - loss: 0.0103 - val_loss: 0.0114 - 64s/epoch - 6s/step
Epoch 43/100
10/10 - 63s - loss: 0.0103 - val_loss: 0.0100 - 63s/epoch - 6s/step
Epoch 44/100
10/10 - 66s - loss: 0.0095 - val_loss: 0.0090 - 66s/epoch - 7s/step
Epoch 45/100
10/10 - 65s - loss: 0.0099 - val_loss: 0.0104 - 65s/epoch - 7s/step
Epoch 46/100
10/10 - 64s - loss: 0.0089 - val_loss: 0.0086 - 64s/epoch - 6s/step
Epoch 47/100
10/10 - 64s - loss: 0.0105 - val_loss: 0.0108 - 64s/epoch - 6s/step
Epoch 48/100
10/10 - 66s - loss: 0.0085 - val_loss: 0.0085 - 66s/epoch - 7s/step
Epoch 49/100
10/10 - 65s - loss: 0.0091 - val_loss: 0.0090 - 65s/epoch - 6s/step
Epoch 50/100
10/10 - 64s - loss: 0.0096 - val_loss: 0.0094 - 64s/epoch - 6s/step
Epoch 51/100
10/10 - 66s - loss: 0.0094 - val_loss: 0.0096 - 66s/epoch - 7s/step
Epoch 52/100
10/10 - 67s - loss: 0.0076 - val_loss: 0.0075 - 67s/epoch - 7s/step
Epoch 53/100
10/10 - 62s - loss: 0.0106 - val_loss: 0.0105 - 62s/epoch - 6s/step
Epoch 54/100
10/10 - 63s - loss: 0.0097 - val_loss: 0.0097 - 63s/epoch - 6s/step
Epoch 55/100
10/10 - 86s - loss: 0.0093 - val_loss: 0.0096 - 86s/epoch - 9s/step
Epoch 56/100
10/10 - 64s - loss: 0.0087 - val_loss: 0.0089 - 64s/epoch - 6s/step
Epoch 57/100
10/10 - 67s - loss: 0.0078 - val_loss: 0.0077 - 67s/epoch - 7s/step
Epoch 58/100
10/10 - 66s - loss: 0.0090 - val_loss: 0.0090 - 66s/epoch - 7s/step
Epoch 59/100
10/10 - 74s - loss: 0.0092 - val_loss: 0.0093 - 74s/epoch - 7s/step
Epoch 60/100
10/10 - 90s - loss: 0.0098 - val_loss: 0.0099 - 90s/epoch - 9s/step
Epoch 61/100
10/10 - 65s - loss: 0.0098 - val_loss: 0.0099 - 65s/epoch - 7s/step
Epoch 62/100
10/10 - 66s - loss: 0.0087 - val_loss: 0.0091 - 66s/epoch - 7s/step
Epoch 63/100
10/10 - 71s - loss: 0.0090 - val_loss: 0.0087 - 71s/epoch - 7s/step
Epoch 64/100
10/10 - 90s - loss: 0.0092 - val_loss: 0.0087 - 90s/epoch - 9s/step
Epoch 65/100
10/10 - 65s - loss: 0.0104 - val_loss: 0.0105 - 65s/epoch - 6s/step
Epoch 66/100
10/10 - 65s - loss: 0.0193 - val_loss: 0.0177 - 65s/epoch - 6s/step
Epoch 67/100
10/10 - 63s - loss: 0.0194 - val_loss: 0.0170 - 63s/epoch - 6s/step
Epoch 68/100
10/10 - 65s - loss: 0.0151 - val_loss: 0.0139 - 65s/epoch - 6s/step
Epoch 69/100
10/10 - 65s - loss: 0.0198 - val_loss: 0.0156 - 65s/epoch - 7s/step
Epoch 70/100
10/10 - 64s - loss: 0.0122 - val_loss: 0.0109 - 64s/epoch - 6s/step
Epoch 71/100
10/10 - 65s - loss: 0.0133 - val_loss: 0.0147 - 65s/epoch - 7s/step
Epoch 72/100
10/10 - 65s - loss: 0.0205 - val_loss: 0.1312 - 65s/epoch - 6s/step
Epoch 73/100
10/10 - 64s - loss: 0.0282 - val_loss: 0.0157 - 64s/epoch - 6s/step
Epoch 74/100
10/10 - 67s - loss: 0.0245 - val_loss: 0.0190 - 67s/epoch - 7s/step
Epoch 75/100
10/10 - 65s - loss: 0.0147 - val_loss: 0.0132 - 65s/epoch - 6s/step
Epoch 76/100
10/10 - 64s - loss: 0.0108 - val_loss: 0.0100 - 64s/epoch - 6s/step
Epoch 77/100
10/10 - 65s - loss: 0.0103 - val_loss: 0.0101 - 65s/epoch - 7s/step
Epoch 78/100
10/10 - 64s - loss: 0.0095 - val_loss: 0.0093 - 64s/epoch - 6s/step
Epoch 79/100
10/10 - 65s - loss: 0.0082 - val_loss: 0.0082 - 65s/epoch - 7s/step
Epoch 80/100
10/10 - 64s - loss: 0.0096 - val_loss: 0.0096 - 64s/epoch - 6s/step
Epoch 81/100
10/10 - 62s - loss: 0.0092 - val_loss: 0.0092 - 62s/epoch - 6s/step
Epoch 82/100
10/10 - 66s - loss: 0.0090 - val_loss: 0.0088 - 66s/epoch - 7s/step
Epoch 83/100
10/10 - 65s - loss: 0.0106 - val_loss: 0.0106 - 65s/epoch - 6s/step
Epoch 84/100
10/10 - 63s - loss: 0.0104 - val_loss: 0.0104 - 63s/epoch - 6s/step
Epoch 85/100
10/10 - 65s - loss: 0.0079 - val_loss: 0.0079 - 65s/epoch - 6s/step
Epoch 86/100
10/10 - 65s - loss: 0.0083 - val_loss: 0.0083 - 65s/epoch - 7s/step
Epoch 87/100
10/10 - 67s - loss: 0.0082 - val_loss: 0.0082 - 67s/epoch - 7s/step
Epoch 88/100
10/10 - 66s - loss: 0.0082 - val_loss: 0.0082 - 66s/epoch - 7s/step
Epoch 89/100
10/10 - 64s - loss: 0.0089 - val_loss: 0.0089 - 64s/epoch - 6s/step
Epoch 90/100
10/10 - 64s - loss: 0.0112 - val_loss: 0.0112 - 64s/epoch - 6s/step
Epoch 91/100
10/10 - 66s - loss: 0.0095 - val_loss: 0.0095 - 66s/epoch - 7s/step
Epoch 92/100
10/10 - 64s - loss: 0.0099 - val_loss: 0.0101 - 64s/epoch - 6s/step
Epoch 93/100
10/10 - 65s - loss: 0.0108 - val_loss: 0.0109 - 65s/epoch - 6s/step
Epoch 94/100
10/10 - 66s - loss: 0.0087 - val_loss: 0.0086 - 66s/epoch - 7s/step
Epoch 95/100
10/10 - 63s - loss: 0.0100 - val_loss: 0.0097 - 63s/epoch - 6s/step
Epoch 96/100
10/10 - 65s - loss: 0.0105 - val_loss: 0.0105 - 65s/epoch - 7s/step
Epoch 97/100
10/10 - 66s - loss: 0.0074 - val_loss: 0.0075 - 66s/epoch - 7s/step
Epoch 98/100
10/10 - 66s - loss: 0.0084 - val_loss: 0.0086 - 66s/epoch - 7s/step
Epoch 99/100
10/10 - 66s - loss: 0.0079 - val_loss: 0.0085 - 66s/epoch - 7s/step
Epoch 100/100
10/10 - 66s - loss: 0.0085 - val_loss: 0.0081 - 66s/epoch - 7s/step
